---
layout: post
title:  "H.264 解析"
author: "daweibayu"
tags: protocol
excerpt_separator: <!--more-->
---

<!--more-->

## 简介


H.264（Advanced Video Coding），目前（2024）为止应用最广泛的视频压缩标准。具体协议本身在 ISO/IEC 14496-10 (MPEG-4 Part 10) 中。
关于 MPEG 的详述可以参看 [MP4 解析](https://daweibayu.fun/2024-11-11/mp4) 。14496-10 协议本身是付费的，最新版本大家自己搜索吧，这里提供一个 [14496-10:2004](http://www.staroceans.org/e-book/ISO-14496-10.pdf) 版本。

x.264 是 H.264 的一个开源实现，源码参看 [videolan - x264](https://code.videolan.org/videolan/x264)，本文也会引用部分源码用于展示 H.254 的具体逻辑。


易混名词解释：

* [codec](https://en.wikipedia.org/wiki/Video_codec)：简而言之就是 /software/  or /hardware/，就是具体工具，例如 x264
* [coding](https://en.wikipedia.org/wiki/Video_coding_format)：编码格式 or 编码标准，例如 H.264
* [container](https://en.wikipedia.org/wiki/Container_format)：容器格式，类似 mp4 等**文件格式**



编码最核心目的是数据压缩，本文主要聚焦于编码过程中的**结构**。


### 输入输出

x264 命令行示例：

```
x264 --input-res 1920x1080 --fps 30 -o output.mp4 yuv420.yuv
```

由上可以看出，输入为 `yuv420.yuv`，输出为 `output.mp4`，可以简单理解成 H.264 的（编码部分）内容就是将原始视频压缩为 mp4（由 mp4box 封装） 格式（或其他格式）。

（几乎所有）视频编码（如 H.264、H.265 等）的国际标准都使用 YUV 作为基础色彩空间，并对其进行了高度优化。至于为什么用 YUV 而不是 RGB，大家可以自行 chatgpt。


### 编码流程

1.	分帧处理：将视频分为宏块，并分别处理亮度和色度分量。
2.	运动估计与补偿：通过运动矢量预测视频帧，减少冗余数据。
3.	变换与量化：对每个宏块的亮度和色度数据进行 DCT 变换，并量化。
4.	熵编码（CABAC/CAVLC）：对量化后的数据进行高效编码，进一步压缩。
5.	帧类型与帧间压缩：利用 I 帧、P 帧、B 帧进行帧间压缩，降低数据量。
6.	数据封装与输出：将压缩后的视频数据封装成最终的输出格式。


### x264 主要数据结构

* [x264_t::mb](https://code.videolan.org/videolan/x264/-/blob/master/common/common.h?ref_type=heads#L438)：macroblock，宏块，分块的基本单位
* [x264_image_t](https://code.videolan.org/videolan/x264/-/blob/master/x264.h?ref_type=heads#L798)：待编码的图像
* [x264_picture_t](https://code.videolan.org/videolan/x264/-/blob/master/x264.h?ref_type=heads#L862)：x264编码视频帧（面向上层）
* [x264_param_t](https://code.videolan.org/videolan/x264/-/blob/master/x264.h?ref_type=heads#L310)：编码器的参数
* [x264_frame_t](https://code.videolan.org/videolan/x264/-/blob/master/common/frame.h?ref_type=heads#L37)：视频帧的核心结构（面向底层，注意与 x264_picture_t 区别）
* [x264_t](https://code.videolan.org/videolan/x264/-/blob/master/common/common.h?ref_type=heads#L270)：

## 详细流程


### 分帧处理

大概步骤如下：

1.	根据具体参数读取和解析 YUV 数据
2.	将解析得到的帧据存储到 x264_picture_t、x264_frame_t 等结构中
3.	（默认）按 16×16 来分割帧数据进行宏块划分
4.	预处理（颜色空间调整、去噪或帧缩放等操作）
5.	将帧传递给编码器进行编码


其中宏块划分如下图：

![MBSplit.png](/assets/images/G2Ul7jkdrTlNqJYptd.png)

即默认宏块大小为 16*16，可划分为 16*8、8*16 或 8*8；而 8*8 的子宏块又可划分为 8*4、4*8 或 4*4。


宏块类型对应到 x264 代码则是 [mb_class_e](https://code.videolan.org/videolan/x264/-/blob/master/common/macroblock.h?ref_type=heads#L64)、[mb_partition_e](https://code.videolan.org/videolan/x264/-/blob/master/common/macroblock.h?ref_type=heads#L115)

各步骤的关键函数如下图，具体也可以看 [example.c](https://code.videolan.org/videolan/x264/-/blob/master/example.c) 了解函数调用时序：

| 步骤           | 关键文件         | 关键函数                                    | 描述                           |
|---------------|-----------|-------------------------|---------------------------|
| 读取和解析 YUV 数据 | `common/frame.c`     | `x264_picture_alloc`, 外部读取逻辑              | 分配内存，初始化 YUV 数据。         |
| 填充到帧结构        | `common/frame.h`     | `x264_encoder_encode`                          | 将 YUV 数据转化为帧结构。           |
| 宏块划分            | `encoder/macroblock.c` | `x264_macroblock_cache_load`, `x264_macroblock_analyse` | 宏块数据划分与加载。                |
| 预处理和时间戳关联   | `common/mc.c`        | `x264_frame_filter`                            | 边缘扩展、滤波和时间戳管理。         |
| 传递到编码器        | `encoder/encoder.c`  | `x264_encoder_encode`                          | 帧传递并完成编码，输出 NAL 单元。    |



### 运动估计与补偿

### 变换与量化

### 熵编码

### 帧类型与帧间压缩

#### **I帧**

1. 
   - I帧是帧内编码帧的缩写。它是一种独立编码的视频帧，不依赖于其他视频帧的信息进行编码。也就是说，I帧可以单独解码出完整的图像内容。
   - 例如，在一个视频序列中，I帧就像是一个完整的“关键画面”。它包含了一帧图像的全部信息，包括亮度、色度等所有细节。当视频播放时，播放器可以直接从I帧获取完整的画面来显示。I帧通常用于随机访问点，比如用户在视频中进行快进、快退操作后，能够快速定位并开始播放的位置往往就是I帧的位置。
2. **B帧**
   - B帧是双向预测编码帧的缩写。B帧在编码时会参考它前面和后面的视频帧（I帧或P帧）来获取更准确的预测信息，从而达到更高的压缩效率。
   - 例如，假设有一个视频序列是A（I帧）、B（P帧）、C（B帧）、D（P帧）。那么C帧（B帧）在编码的时候会同时参考B帧和D帧的信息。这种双向参考的方式使得B帧能够去除更多的时间冗余信息，在压缩方面比I帧和P帧更有优势。不过，由于B帧需要前后帧的信息才能正确解码，所以它的解码顺序和播放顺序可能不同。
3. **P帧**
   - P帧是前向预测编码帧的缩写。P帧在编码时是通过参考前面的I帧或者P帧来进行预测编码的。它主要利用了视频信号在时间上的相关性，通过对前面已编码帧的运动估计和补偿来编码当前帧。
   - 例如，还是上面的视频序列A（I帧）、B（P帧）、C（B帧）、D（P帧）。B帧（P帧）在编码的时候会参考A帧的信息，通过分析A帧到B帧之间物体的运动情况，来编码B帧。这样可以减少存储和传输时的数据量，因为只需要记录与前一帧的差异部分就可以了。P帧对于视频的流畅播放和高效压缩也起到了很重要的作用。
